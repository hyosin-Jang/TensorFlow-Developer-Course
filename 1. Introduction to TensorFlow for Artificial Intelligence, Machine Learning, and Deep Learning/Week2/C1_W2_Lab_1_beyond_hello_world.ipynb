{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "C1_W2_Lab_1_beyond_hello_world.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuB3pv5yhKbb",
        "outputId": "23d32ef0-28d3-4ec5-cecc-3d9bc6061ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_n1U5do3u_F"
      },
      "source": [
        "The [Fashion MNIST dataset](https://github.com/zalandoresearch/fashion-mnist) is a collection of grayscale 28x28 pixel clothing images. Each image is associated with a label as shown in this table‚Åâ\n",
        "\n",
        "| Label | Description |\n",
        "| --- | --- |\n",
        "| 0 | T-shirt/top |\n",
        "| 1 | Trouser |\n",
        "| 2 | Pullover |\n",
        "| 3 | Dress |\n",
        "| 4 | Coat |\n",
        "| 5 | Sandal |\n",
        "| 6 | Shirt |\n",
        "| 7 | Sneaker |\n",
        "| 8 | Bag |\n",
        "| 9 | Ankle boot |\n",
        "\n",
        "This dataset is available directly in the [tf.keras.datasets](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) API and you load it like this:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Fashion MNIST dataset\n",
        "fmnist = tf.keras.datasets.fashion_mnist"
      ],
      "metadata": {
        "id": "SraIm9iJhTlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling load_data() on this object will give you two tuples with two lists each. These will be the training and testing values for the graphics that contain the clothing items and their labels."
      ],
      "metadata": {
        "id": "eiM8crJ1huMf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the training and test split of the Fashion MNIST dataset\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROXoALu7htL9",
        "outputId": "2f1d4160-725b-495a-dfe4-cc5dcdec803a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ïù¥ÎØ∏ÏßÄ ÌîÑÎ¶∞Ìä∏ÌïòÍ∏∞"
      ],
      "metadata": {
        "id": "aEKWL5FYiFCK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does these values look like? Let's print a training image (both as an image and a numpy array), and a training label to see. Experiment with different indices in the array. For example, also take a look at index 42. That's a different boot than the one at index 0."
      ],
      "metadata": {
        "id": "ze0M30PHiCkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ÌõàÎ†®Ïö© Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÍ∞Ä 6ÎßåÍ∞úÏù¥ÎØÄÎ°ú 0-59999ÍπåÏßÄ ÌôïÏù∏Ìï¥ Î≥º Ïàò ÏûàÏùå\n",
        "index = 49\n",
        "\n",
        "# ÌîÑÎ¶∞Ìä∏Ìï† Îïå Ìïú Ï§ÑÏóê Ï∂úÎ†•ÎêòÎäî Ï∫êÎ¶≠ÌÑ∞ Í∞úÏàò ÏÑ§Ï†ï\n",
        "np.set_printoptions(linewidth=320)\n",
        "\n",
        "# ÎùºÎ≤®, Ïù¥ÎØ∏ÏßÄ Ï∂úÎ†•\n",
        "print(f'LABEL: {training_labels[index]}')\n",
        "print(f'\\nIMAGE PIXEL ARRAY:\\n {training_images[index]}')\n",
        "\n",
        "# Visualize the image\n",
        "plt.imshow(training_images[index])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 846
        },
        "id": "GD_lYY-Ch8oq",
        "outputId": "73458d14-7df4-4607-d7ac-64e97ca439f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 3\n",
            "\n",
            "IMAGE PIXEL ARRAY:\n",
            " [[  0   0   0   0   0   0   0   0   0   0   0  83 152  57  84 166 113  31   0   0   0   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   3   0   0 174 210 227 252 226 231 249 225 220 234  82   0   2   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 177 242 213 211 212 219 215 207 211 212 223 230  43   0   5   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 195 220 214 215 217 215 215 216 215 214 205 229 130   0   2   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 208 222 215 213 215 216 217 216 214 212 214 226 169   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  30 222 227 236 213 215 217 218 217 218 211 225 226 183   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0  67 243 185 144 250 215 218 219 220 228 207 140 231 203   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 104 248 148  75 254 212 219 220 222 228 216  53 229 219  21   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 144 249 148  55 255 210 221 219 219 228 219   1 220 231  57   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 158 248  67  24 255 209 219 219 216 232 217   0 206 244 101   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 179 231   0  49 253 210 223 220 221 227 228   0 112 251 129   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 203 251   0 106 252 212 220 221 219 212 252   0  65 251 141   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 212 245   0 215 242 217 220 219 217 211 254  48  84 252 163   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 213 218  53 252 223 220 222 223 222 216 249 157 149 246 192   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  15 251 224 175 236 224 224 224 224 223 222 226 213 216 232 228   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  50 252 227 243 225 226 225 224 223 223 225 221 218 233 225 245   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0  72 251 227 239 221 225 224 224 223 223 224 223 214 233 226 252   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 105 252 226 237 222 225 224 223 223 223 223 224 217 230 226 221   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 152 225 223 233 222 226 224 227 221 223 225 225 217 229 221 229  35   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0 146 248 241 229 224 226 224 233 221 222 225 227 220 234 249 227  18   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0 106 166 243 222 226 225 235 224 220 227 220 243 161 130  62   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  31 254 217 227 226 238 224 221 226 222 252 144   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   2   0 123 240 223 227 225 240 223 223 225 223 235 209   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 162 241 224 228 228 243 224 223 227 227 230 233   0   0   1   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 193 237 225 228 231 244 226 226 228 228 229 215   0   0   4   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 212 230 223 224 228 236 216 218 220 226 223 232  34   0   6   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 219 243 241 254 255 255 254 253 254 244 240 249 100   0   6   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 118 114  65  23 108 159 130  71  87 141  89   0   0   1   0   0   0   0   0]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fba85ea14d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalization"
      ],
      "metadata": {
        "id": "34q9WuvMkGo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "All of the values in the number are between 0 and 255, but it's good to rescale all values to between 0 and 1. It's process normalization"
      ],
      "metadata": {
        "id": "8t01i0Dsj4mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the pixel values of the train and test images\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "d2HolKNHj2w8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model design"
      ],
      "metadata": {
        "id": "fwtz-a5ekWkF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the classification model\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation = tf.nn.softmax)])"
      ],
      "metadata": {
        "id": "xADllbODkXn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential: That defines a sequence of layers in the neural network.</br>\n",
        "Flatten: Flatten just turns 28x28 pixels into a 1-dimensional array.<br/>\n",
        "Dense: Adds a layer of neurons\n",
        "(Í∞ÅÍ∞ÅÏùò Îâ¥Îü∞ÏùÄ ÌôúÏÑ±Ìôî Ìï®Ïàò ÌïÑÏöîÌï®) "
      ],
      "metadata": {
        "id": "SOfuoFZ8k8lj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU\n",
        "\n",
        "```\n",
        "if x > 0:\n",
        " return x\n",
        "else:\n",
        " return 0\n",
        "```\n",
        "ReLU only passes values 0 or greater to the next layer in the network. </br>\n",
        "(0 Ïù¥ÏÉÅÏù∏ Í∞íÏùÄ Í∑∏ÎåÄÎ°ú Ï∂úÎ†•, 0 Ïù¥ÌïòÎäî 0ÏúºÎ°ú Ï∂úÎ†•)\n",
        "\n"
      ],
      "metadata": {
        "id": "-Irkh_pplYDB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Softmax\n",
        "Softmax takes a list of values and scales these so the sum of all elements will be equal to 1.\n",
        "ÏòàÎ•º Îì§Ïñ¥, output dense layerÏóê 10Í∞úÏùò ÌçºÏÖâÌä∏Î°†Ïù¥ ÏûàÏùÑ Îïå, index=4Ïùò Í∞íÏù¥ Í∞ÄÏû• ÌÅ¨Îã§Îäî Í≤ÉÏùÄ Î™®Îç∏Ïù¥ coatÎùºÍ≥† ÏòàÏ∏°Ìï† ÌôïÎ•†Ïù¥ Í∞ÄÏû• ÎÜíÎã§Îäî Í≤ÉÏùÑ ÏùòÎØ∏Ìï®."
      ],
      "metadata": {
        "id": "glqWSChal3m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare sample inputs and convert to a tensor\n",
        "inputs = np.array([[1.0, 3.0, 4.0, 2.0]])\n",
        "inputs = tf.convert_to_tensor(inputs)\n",
        "print(f'Input to softmax fnction: {inputs.numpy()}')\n",
        "\n",
        "# Feed the inputs to a softmax activation function\n",
        "outputs = tf.keras.activations.softmax(inputs)\n",
        "print(f'output of the softmax function: {outputs.numpy()}')\n",
        "\n",
        "# Get the sum of all values after the softmax\n",
        "# Î™®Îì† ÌôïÎ•†Ïùò Ìï©ÏùÄ 1\n",
        "sum = tf.reduce_sum(outputs)\n",
        "print(f'sum of the outputs: {sum}')\n",
        "\n",
        "# Get the index with highest value\n",
        "prediction = np.argmax(outputs) # Í∞ÄÏû• ÌÅ∞ Í∞íÏùò Ïù∏Îç±Ïä§ Î∞òÌôò\n",
        "print(f'class with highest probability: {prediction}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5C_Antek4nl",
        "outputId": "bfc5f15e-bbbf-4ed0-f39d-deccbf254499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input to softmax fnction: [[1. 3. 4. 2.]]\n",
            "output of the softmax function: [[0.0320586  0.23688282 0.64391426 0.08714432]]\n",
            "sum of the outputs: 1.0\n",
            "class with highest probability: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compiling with optimizer and loss function"
      ],
      "metadata": {
        "id": "RtbU8WoCnBgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.optimizers.Adam(), \n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.fit()ÏúºÎ°ú trainÌïòÍ∏∞, training dataÏóê training labels Î∂ôÏó¨Ï§å\n",
        "model.fit(training_images, training_labels, epochs=5) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iN2y-3QnBPG",
        "outputId": "88f4399f-eade-48ae-a74d-3cbb596e0902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5019 - accuracy: 0.8257\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3796 - accuracy: 0.8637\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3372 - accuracy: 0.8776\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3138 - accuracy: 0.8841\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2960 - accuracy: 0.8913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba81693bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accuracy\n",
        "test accuracy: 0.8739\n",
        "it means 87% accurate on the entire test data set. "
      ],
      "metadata": {
        "id": "8VZbPQGKniBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on unseen data\n",
        "# ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞Î°ú Í≤ÄÏ¶ùÌïòÍ∏∞\n",
        "model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKf7Ux2vnjK-",
        "outputId": "e67bcb6b-3d10-4a1c-90d7-9c5b4d9620a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3424 - accuracy: 0.8739\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3423924744129181, 0.8738999962806702]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise 1"
      ],
      "metadata": {
        "id": "bov_6NDEn-L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "list is the probability that this item is each of the 10 classes. </br>\n",
        "These numbers are a probability that the value being classified is the corresponding value"
      ],
      "metadata": {
        "id": "Zr9Ko83Toeco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XncXwDd2n978",
        "outputId": "3404308a-0241-4226-c277-2ef111e115fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.8107307e-06 9.9997211e-01 1.1733305e-07 2.5687725e-05 1.5345528e-07 8.6884937e-11 1.8902917e-07 2.7528981e-11 1.0942761e-10 4.4083917e-11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_labels[3])\n",
        "# 9.9997211e-01"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GJF0BNomnrg",
        "outputId": "34174c8d-1f00-4b59-8a0c-f429fa4fff74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2"
      ],
      "metadata": {
        "id": "SuUgHbwHpTkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGpdg0pkkQFE",
        "outputId": "35db6c6a-b05d-49b2-fa3a-95934d241cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.1849\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0751\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0479\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0348\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0250\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0714\n",
            "[2.9479078e-10 1.5649539e-09 3.8117358e-09 1.4769955e-06 4.6475542e-11 2.5877026e-10 3.3843802e-13 9.9999642e-01 1.1574428e-09 2.1995040e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We increase to 1024 neurons\n",
        "Training takes longer, but is more accurate.</br>\n",
        "Because by adding more neurons we have to do more calculations, slowing down the process, <br>but they have a good impact üëâ we do get more accurate."
      ],
      "metadata": {
        "id": "4mXt3u6jqFW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What would happen if you remove the Flatten() layer?\n",
        "I will get an error about the shape of the data.<br>\n",
        "It reinforces the rule of thumb that the first layer in the network should be the same shape as your data.<br>\n",
        "The data is 28x28 images, and 28 layers of 28 neurons would be infeasible,.. <br>\n",
        "so it makes sense to flatten that 28x28 into a 784x1.\n",
        "\n",
        "### Error message: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)"
      ],
      "metadata": {
        "id": "Yxmv9sBKqqat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 795
        },
        "id": "goC5AU5rqltM",
        "outputId": "8d949473-2fd2-4156-ef32-29eeb44fbad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-8a69f00bb9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1738, in sparse_categorical_crossentropy\n        y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5114, in sparse_categorical_crossentropy\n        labels=target, logits=output)\n\n    ValueError: `labels.shape` must equal `logits.shape` except for the last dimension. Received: labels.shape=(32,) and logits.shape=(896, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4\n",
        "Consider the final layers, why are there 10 of them?\n",
        "ÎßåÏïΩ ÎßàÏßÄÎßâ Î†àÏù¥Ïñ¥Ïùò Îâ¥Îü∞ Í∞úÏàòÍ∞Ä 10Í∞úÎ≥¥Îã§ ÎßéÎã§Î©¥?"
      ],
      "metadata": {
        "id": "yvh48oXqrrNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(15, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQHeY2eHrrcb",
        "outputId": "254a181e-caf9-4437-84f1-a00f13b3f765"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.1885\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0738\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0476\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 15s 8ms/step - loss: 0.0343\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0275\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0634\n",
            "[4.1836596e-09 9.0397814e-09 2.1491071e-07 1.8119828e-04 1.3515736e-12 6.6755773e-10 2.2019491e-12 9.9981731e-01 1.1939342e-08 1.3168908e-06 2.1430661e-12 1.8077121e-12 3.1107946e-12 1.2033073e-12 4.4590338e-12]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I get an error because it finds an unexpected value.\n",
        "<br>Another rule of thumb - the number of neurons in the last layer should match the number of classes you are classifying for."
      ],
      "metadata": {
        "id": "6_hazS4IsDTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 5\n",
        "Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10."
      ],
      "metadata": {
        "id": "1o_Hi3AYsWq0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBN0f6uVsWdF",
        "outputId": "00d1bc66-1bac-4d51-ac03-3d156e0fe25f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2245\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0954\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0659\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0517\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0399\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0809\n",
            "[9.08641551e-10 2.31331665e-08 1.09186935e-07 7.17206383e-09 3.24183458e-09 3.11157056e-09 1.76035174e-12 9.99998450e-01 1.19077290e-08 1.46826449e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Answer:\n",
        "There isn't a signimicant impact.\n",
        "Because this is simple data.\n",
        "But, for far more complex data (including color images) extra layers are often necessary."
      ],
      "metadata": {
        "id": "ZXmTEck9ssPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 6\n",
        "Consider the impact of training for more or less epochs. What would be the best case?\n",
        "- Try 15 epochs üëâ You'll probably get a model with a much better loss than one with 5. (ÏÑ±Îä• Í∞úÏÑ†Îê®)\n",
        "- Try 30 epochs üëâ You might see loss value stop decreasing, and sometimes increases. (Ïò§Î≤ÑÌîºÌåÖ Î∞úÏÉù)"
      ],
      "metadata": {
        "id": "aDP1K62zs7fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=15) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwYbwsVssA1N",
        "outputId": "7f589026-05b2-4203-d764-626a7e679792"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2570\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1128\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0762\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0586\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0443\n",
            "Epoch 6/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0365\n",
            "Epoch 7/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0282\n",
            "Epoch 8/15\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0224\n",
            "Epoch 9/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0194\n",
            "Epoch 10/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0148\n",
            "Epoch 11/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0135\n",
            "Epoch 12/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0097\n",
            "Epoch 13/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0097\n",
            "Epoch 14/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0081\n",
            "Epoch 15/15\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0090\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0969\n",
            "[2.9064076e-14 3.6411561e-11 6.1697243e-08 5.4853626e-08 5.1967147e-20 1.9009384e-18 1.7102016e-19 9.9999988e-01 6.4051930e-11 5.7722842e-13]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMC0HTP7tMkx",
        "outputId": "e8b6182e-3693-435b-8aff-b9ef00d335ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2583\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1139\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0774\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0596\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0456\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0357\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0306\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0239\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0194\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0156\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0131\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0121\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0111\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0092\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0085\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0080\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0069\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0065\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0056\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0059\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0051\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0057\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0052\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0044\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0050\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0046\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0041\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0048\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0033\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0037\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1506\n",
            "[7.9545957e-22 1.9649098e-21 4.4531997e-13 2.2189424e-09 2.5928159e-28 2.8317865e-32 4.9766940e-32 1.0000000e+00 4.2374957e-17 3.5738956e-20]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 7\n",
        "Before you trained, 0-255Î•º 0-1Î°ú normalizeÌïòÎäî Í≥ºÏ†ï ÏóÜÏï†Î©¥ Ïñ¥ÎñªÍ≤å Îê†Íπå?"
      ],
      "metadata": {
        "id": "cmHHKRS1uKo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# training_images = training_images / 255.0 # Ïù¥Í±∞ Ï†úÍ±∞Ìï¥Î≥¥Í∏∞\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vY5X8NUuujDK",
        "outputId": "40da856a-615a-48e3-abaf-8da5489fca37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 2.4163\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3601\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2925\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2471\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2344\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2178\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2030\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2025\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1934\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1877\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1784\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1843\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1778\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1673\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1753\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1650\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1598\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1609\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1567\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1615\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1579\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1569\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1551\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.1493\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1543\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1508\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1511\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.1507\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1464\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.1502\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4559\n",
            "[0.0000000e+00 1.1269180e-10 2.3659199e-17 5.9213905e-09 3.2053259e-38 7.2737519e-22 0.0000000e+00 1.0000000e+00 1.9781293e-23 5.7684286e-22]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 8\n",
        "\n",
        "- ÏõêÌïòÎäî Ï†ïÌôïÎèÑ ÎèÑÎã¨ÌïòÎ©¥ ÌõàÎ†® ÎÅùÎÇ¥Î≥¥Í∏∞\n",
        "- tf.keras.callbacksÏùò Callback Í∞ùÏ≤¥ Ïù¥Ïö©"
      ],
      "metadata": {
        "id": "VHyov9JLvGlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.98):\n",
        "      print(\"\\n Reached 98% accuracy so canceling training \")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks = [callbacks]) \n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nSmcIsCvGPw",
        "outputId": "3fa02a7f-b7ca-4c5f-9416-71af73d948d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.2065 - accuracy: 0.9383\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0822 - accuracy: 0.9747\n",
            "Epoch 3/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.0527 - accuracy: 0.9834\n",
            " Reached 50% accuracy so canceling training \n",
            "1875/1875 [==============================] - 10s 6ms/step - loss: 0.0526 - accuracy: 0.9834\n",
            "313/313 [==============================] - 10s 3ms/step - loss: 0.0746 - accuracy: 0.9766\n",
            "[1.1570433e-12 8.5984180e-09 6.5135612e-07 4.9845689e-06 2.9529348e-12 3.6978593e-12 1.0729857e-13 9.9999428e-01 7.2893037e-08 4.2426245e-09]\n",
            "7\n"
          ]
        }
      ]
    }
  ]
}